{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "oFbhAxB1h_XF",
        "outputId": "dbc05471-9e52-4832-c5a5-03954f13bc68"
      },
      "outputs": [],
      "source": [
        "!pip install supervision Pillow ultralytics numpy opencv-python inference-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n_aEnUWE4ss2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "\n",
        "# Initialize models and components\n",
        "vehicle_model = YOLO(\"yolov8n.pt\")  # YOLOv8 for vehicle detection\n",
        "\n",
        "\n",
        "# Define output video path\n",
        "video_path = \"/content/test.mp4\"\n",
        "output_video_path = \"/content/output.mp4\"\n",
        "output_fps = 30  # Adjust this based on your input video's frame rate\n",
        "frame_size = None  # Will be set dynamically based on the first frame\n",
        "\n",
        "# Initialize the video writer\n",
        "video_writer = None\n",
        "\n",
        "client = InferenceHTTPClient(\n",
        "    api_url=\"https://detect.roboflow.com\",\n",
        "    api_key=\"L5uh8sOgmpA0sglsoQzM\"  # Replace this with your actual API key\n",
        ")\n",
        "\n",
        "license_plate_model_id = \"license-plate-recognition-rxg4e/6\"\n",
        "\n",
        "# Tracking and annotators\n",
        "tracker = sv.ByteTrack()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# Vehicle classes (COCO IDs)\n",
        "VEHICLE_CLASSES = {2: \"car\", 5: \"bus\", 7: \"truck\"}\n",
        "\n",
        "frames_generator = sv.get_video_frames_generator(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "lHZRv96q9Ywc"
      },
      "outputs": [],
      "source": [
        "def matricule(frame):\n",
        "    try:\n",
        "        # Perform inference on the frame\n",
        "        result = client.infer(frame, model_id=license_plate_model_id)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error during inference: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FuhT8g1oFUQT"
      },
      "outputs": [],
      "source": [
        "# Callback function for vehicle detection\n",
        "def process_vehicles(frame: np.ndarray) -> np.ndarray:\n",
        "    results = vehicle_model(frame)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    mask = np.isin(detections.class_id, list(VEHICLE_CLASSES.keys()))\n",
        "    detections = detections[mask]\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {VEHICLE_CLASSES[class_id]}\"\n",
        "        for class_id, tracker_id in zip(detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "    annotated_frame = box_annotator.annotate(frame.copy(), detections=detections)\n",
        "    return label_annotator.annotate(annotated_frame, detections=detections, labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fr9HVEgsDYn0",
        "outputId": "bd32e6e2-aede-4d90-a71f-1e0db9349dd5"
      },
      "outputs": [],
      "source": [
        "for idx, frame in enumerate(frames_generator):\n",
        "    # Process vehicles on the frame\n",
        "    annotated_frame = process_vehicles(frame)\n",
        "\n",
        "    # Perform license plate recognition\n",
        "    try:\n",
        "        result = client.infer(frame, model_id=license_plate_model_id)\n",
        "        if result and \"predictions\" in result:\n",
        "            predictions = result[\"predictions\"]\n",
        "            for prediction in predictions:\n",
        "                # Extract license plate bounding box\n",
        "                x, y, width, height = prediction[\"x\"], prediction[\"y\"], prediction[\"width\"], prediction[\"height\"]\n",
        "                confidence = prediction[\"confidence\"]\n",
        "                label = prediction[\"class\"]\n",
        "\n",
        "                # Convert center-based box to corner-based coordinates\n",
        "                left = int(x - width / 2)\n",
        "                top = int(y - height / 2)\n",
        "                right = int(x + width / 2)\n",
        "                bottom = int(y + height / 2)\n",
        "\n",
        "                # Draw license plate bounding box\n",
        "                cv2.rectangle(annotated_frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "                cv2.putText(\n",
        "                    annotated_frame,\n",
        "                    f\"{label} ({confidence:.2f})\",\n",
        "                    (left, top - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    (0, 0, 255),\n",
        "                    2,\n",
        "                )\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing license plate on frame {idx}: {e}\")\n",
        "\n",
        "    # Initialize the video writer if not done yet\n",
        "    if video_writer is None:\n",
        "        frame_size = (annotated_frame.shape[1], annotated_frame.shape[0])  # (width, height)\n",
        "        video_writer = cv2.VideoWriter(\n",
        "            output_video_path,\n",
        "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "            output_fps,\n",
        "            frame_size\n",
        "        )\n",
        "\n",
        "    # Write annotated frame to output video\n",
        "    video_writer.write(annotated_frame)\n",
        "\n",
        "# Release the video writer\n",
        "if video_writer:\n",
        "    video_writer.release()\n",
        "\n",
        "print(\"Video processing complete. Saved to:\", output_video_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
