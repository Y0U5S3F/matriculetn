{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yV4t9LetLRP8",
        "outputId": "1a29924e-74f0-4c3b-94b1-b039af591952"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install opencv-python-headless moviepy\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Download YOLO weights and config files\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights -O yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg -O yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names -O coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "PNCD3GsLifuM"
      },
      "outputs": [],
      "source": [
        "def detect_yolo(input_image_path):\n",
        "    # Load YOLO model\n",
        "    net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "    with open(\"coco.names\", \"r\") as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # Set up detection layers\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    # Load your image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    height, width, channels = image.shape\n",
        "    # Prepare image for YOLO\n",
        "    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "    # Extract bounding boxes and class IDs\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    results = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:  # Confidence threshold\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "                results.append({\n",
        "                    \"class\": classes[class_id],\n",
        "                    \"confidence\": float(confidence),\n",
        "                    \"x\": x,\n",
        "                    \"y\": y,\n",
        "                    \"width\": w,\n",
        "                    \"height\": h\n",
        "                })\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nOmUltTtRIEP"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define Non-Maximum Suppression (NMS) Function\n",
        "def non_max_suppression(boxes, confidences, iou_threshold=0.4):\n",
        "    # Convert boxes to x1, y1, x2, y2 format\n",
        "    converted_boxes = np.array([[x, y, x + w, y + h] for x, y, w, h in boxes])\n",
        "    confidences = np.array(confidences)\n",
        "\n",
        "    # Perform NMS using OpenCV\n",
        "    indices = cv2.dnn.NMSBoxes(\n",
        "        bboxes=converted_boxes.tolist(),\n",
        "        scores=confidences.tolist(),\n",
        "        score_threshold=0.5,\n",
        "        nms_threshold=iou_threshold\n",
        "    )\n",
        "    return indices.flatten() if len(indices) > 0 else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "DKZEdtt-iqUz"
      },
      "outputs": [],
      "source": [
        "# Step 3: Apply NMS to Filter Boxes\n",
        "def filter_boxes(results, iou_threshold=0.4):\n",
        "    # Extract bounding box coordinates and confidence scores\n",
        "    boxes = [[item[\"x\"], item[\"y\"], item[\"width\"], item[\"height\"]] for item in results]\n",
        "    confidences = [item[\"confidence\"] for item in results]\n",
        "\n",
        "    # Perform NMS\n",
        "    nms_indices = non_max_suppression(boxes, confidences, iou_threshold)\n",
        "\n",
        "    # Filter the results\n",
        "    return [results[i] for i in nms_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "KtBHUQ-TisfA"
      },
      "outputs": [],
      "source": [
        "# Step 4: Draw Borders from Filtered JSON\n",
        "def draw_boxes_from_json(input_image_path, json_data):\n",
        "    # Load the image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    base_name = input_image_path.split(\"/\")[3][0:-4]\n",
        "\n",
        "    # Draw each box\n",
        "    for box in json_data:\n",
        "        x, y, w, h = box[\"x\"], box[\"y\"], box[\"width\"], box[\"height\"]\n",
        "        label = box[\"class\"]\n",
        "        confidence = box[\"confidence\"]\n",
        "        color = (0, 255, 0)  # Green for vehicles\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "        text = f\"{label} {confidence:.2f}\"\n",
        "        cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    # Save the filtered JSON data to a file\n",
        "    output_json_path = f\"/content/borders/{base_name}.json\"\n",
        "    with open(output_json_path, \"w\") as json_file:\n",
        "        json.dump(json_data, json_file, indent=4)\n",
        "    print(f\"Filtered JSON saved to {output_json_path}\")\n",
        "\n",
        "    # Save the output image\n",
        "    cv2.imwrite(f\"/content/outputs/{base_name}_bordered.jpg\", image)\n",
        "    print(f\"Result saved to /content/outputs/{base_name}_bordered.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20lFXudixH3",
        "outputId": "3b61e4a4-144c-4bb5-abd5-d52d8b8a8ca4"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/originals/\"\n",
        "images = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
        "for input_image_path in images:\n",
        "    results = detect_yolo(input_image_path)\n",
        "    # Filter bounding boxes using NMS\n",
        "    filtered_data = filter_boxes(results, iou_threshold=0.4)\n",
        "\n",
        "    # Draw and save the results on the image\n",
        "    draw_boxes_from_json(input_image_path, filtered_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De703oWqiyVG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
