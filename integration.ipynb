{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install opencv-python-headless numpy ultralytics inference-sdk easyocr supervision tensorflow"],"metadata":{"id":"F2Y8n2H93ubR","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"154c489f-a546-4ada-a4e4-1769a119f55f","collapsed":true,"executionInfo":{"status":"ok","timestamp":1734447629240,"user_tz":-60,"elapsed":15384,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Collecting ultralytics\n","  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\n","Collecting inference-sdk\n","  Downloading inference_sdk-0.31.1-py3-none-any.whl.metadata (11 kB)\n","Collecting easyocr\n","  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n","Collecting supervision\n","  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n","Collecting dataclasses-json~=0.6.0 (from inference-sdk)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pillow>=7.1.2 (from ultralytics)\n","  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n","Collecting aiohttp<=3.10.11,>=3.9.0 (from inference-sdk)\n","  Downloading aiohttp-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting backoff~=2.2.0 (from inference-sdk)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n","Collecting python-bidi (from easyocr)\n","  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n","Collecting pyclipper (from easyocr)\n","  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n","Collecting ninja (from easyocr)\n","  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.18.3)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (4.0.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json~=0.6.0->inference-sdk)\n","  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json~=0.6.0->inference-sdk)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.36.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.9.20)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-sdk)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<=3.10.11,>=3.9.0->inference-sdk) (0.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading inference_sdk-0.31.1-py3-none-any.whl (33 kB)\n","Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading supervision-0.25.1-py3-none-any.whl (181 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n","Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: python-bidi, pyclipper, pillow, ninja, mypy-extensions, marshmallow, backoff, typing-inspect, ultralytics-thop, supervision, dataclasses-json, aiohttp, ultralytics, inference-sdk, easyocr\n","  Attempting uninstall: pillow\n","    Found existing installation: pillow 11.0.0\n","    Uninstalling pillow-11.0.0:\n","      Successfully uninstalled pillow-11.0.0\n","  Attempting uninstall: aiohttp\n","    Found existing installation: aiohttp 3.11.10\n","    Uninstalling aiohttp-3.11.10:\n","      Successfully uninstalled aiohttp-3.11.10\n","Successfully installed aiohttp-3.10.11 backoff-2.2.1 dataclasses-json-0.6.7 easyocr-1.7.2 inference-sdk-0.31.1 marshmallow-3.23.1 mypy-extensions-1.0.0 ninja-1.11.1.3 pillow-10.4.0 pyclipper-1.3.0.post6 python-bidi-0.6.3 supervision-0.25.1 typing-inspect-0.9.0 ultralytics-8.3.50 ultralytics-thop-2.0.13\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]},"id":"92baeac470d94776ab9062843cd83258"}},"metadata":{}}]},{"cell_type":"code","source":["!pip uninstall -y torch\n","!pip install torch==2.0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gWQMVNw5jIS","outputId":"11b8ae60-bdd7-4a81-b70a-06d882ba20c5","collapsed":true,"executionInfo":{"status":"ok","timestamp":1734447843111,"user_tz":-60,"elapsed":183413,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.5.1+cu121\n","Uninstalling torch-2.5.1+cu121:\n","  Successfully uninstalled torch-2.5.1+cu121\n","Collecting torch==2.0.1\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n","Collecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m826.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"]}]},{"cell_type":"code","source":["!pip install --upgrade ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0P8jxBw5ngT","outputId":"b90f61d3-7293-4cdd-edba-a1406d66d1ff","collapsed":true,"executionInfo":{"status":"ok","timestamp":1734448038871,"user_tz":-60,"elapsed":195768,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.50)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->ultralytics) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->ultralytics) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.30.5)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (18.1.8)\n","Collecting torch>=1.8.0 (from ultralytics)\n","  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting triton==3.1.0 (from torch>=1.8.0->ultralytics)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.0.0\n","    Uninstalling triton-2.0.0:\n","      Successfully uninstalled triton-2.0.0\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n","    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n","    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1\n","    Uninstalling torch-2.0.1:\n","      Successfully uninstalled torch-2.0.1\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import supervision as sv\n","import tensorflow as tf\n","import easyocr\n","import io\n","from PIL import Image\n","from collections import defaultdict, deque\n","from ultralytics import YOLO\n","from google.colab.patches import cv2_imshow\n","from inference_sdk import InferenceHTTPClient\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.utils import img_to_array\n","from tensorflow.keras.preprocessing.image import array_to_img\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt"],"metadata":{"id":"mz6_I8FF3-m6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hardcode paths and default values\n","SOURCE_VIDEO_PATH = \"vehicles.mp4\"   # Input video file\n","OUTPUT_VIDEO_PATH = 'output.mp4'  # Output video file\n","CONFIDENCE_THRESHOLD = 0.5\n","IOU_THRESHOLD = 0.4"],"metadata":{"id":"GQxoPJ-r4CKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the source and target polygons\n","SOURCE = np.array([[1252, 787], [2298, 803], [5039, 2159], [-550, 2159]])\n","TARGET_WIDTH = 25\n","TARGET_HEIGHT = 250\n","TARGET = np.array(\n","    [\n","        [0, 0],\n","        [TARGET_WIDTH - 1, 0],\n","        [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],\n","        [0, TARGET_HEIGHT - 1],\n","    ]\n",")"],"metadata":{"id":"pGEhhtLY4Eoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize view transformer (used for perspective correction)\n","class ViewTransformer:\n","    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n","        source = source.astype(np.float32)\n","        target = target.astype(np.float32)\n","        self.m = cv2.getPerspectiveTransform(source, target)\n","\n","    def transform_points(self, points: np.ndarray) -> np.ndarray:\n","        if points.size == 0:\n","            return points\n","\n","        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n","        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n","        return transformed_points.reshape(-1, 2)"],"metadata":{"id":"wab38nr84IBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the video input and output\n","video_info = sv.VideoInfo.from_video_path(video_path=SOURCE_VIDEO_PATH)\n","model = YOLO(\"yolov8n.pt\")   # Automatically download YOLOv8 model if not already present\n","\n","byte_track = sv.ByteTrack(\n","    frame_rate=video_info.fps, track_activation_threshold=CONFIDENCE_THRESHOLD\n",")\n","modelcustom = tf.keras.models.load_model('license_plate_classifier2.h5')\n","reader = easyocr.Reader(['en'])"],"metadata":{"id":"oLN8J4ol4Qwg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26861f2e-9df5-4083-c8a1-ae6ae3925223","executionInfo":{"status":"ok","timestamp":1734449707846,"user_tz":-60,"elapsed":4843,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"]}]},{"cell_type":"code","source":["# Setup annotators (for drawing on frames)\n","thickness = sv.calculate_optimal_line_thickness(resolution_wh=video_info.resolution_wh)\n","text_scale = sv.calculate_optimal_text_scale(resolution_wh=video_info.resolution_wh)\n","box_annotator = sv.BoxAnnotator(thickness=thickness)\n","label_annotator = sv.LabelAnnotator(\n","    text_scale=text_scale,\n","    text_thickness=thickness,\n","    text_position=sv.Position.BOTTOM_CENTER,\n",")\n","trace_annotator = sv.TraceAnnotator(\n","    thickness=thickness,\n","    trace_length=video_info.fps * 2,\n","    position=sv.Position.BOTTOM_CENTER,\n",")"],"metadata":{"id":"6iZOVrh14TAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_zone = sv.PolygonZone(polygon=SOURCE)\n","view_transformer = ViewTransformer(source=SOURCE, target=TARGET)"],"metadata":{"id":"5b3lmai04WNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize Roboflow client for license plate detection\n","client = InferenceHTTPClient(\n","    api_url=\"https://detect.roboflow.com\",\n","    api_key=\"L5uh8sOgmpA0sglsoQzM\"  # Replace with your actual API key\n",")\n","license_plate_model_id = \"license-plate-recognition-rxg4e/6\"\n","polygon_zone = sv.PolygonZone(polygon=SOURCE)\n","coordinates = defaultdict(lambda: deque(maxlen=video_info.fps))\n","# Generate frames from the input video\n","frame_generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH)"],"metadata":{"id":"B6MESagg4YEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def matricule(frame):\n","    try:\n","        # Perform inference on the frame using Roboflow's license plate detection model\n","        result = client.infer(frame, model_id=license_plate_model_id)\n","        return result\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        return None"],"metadata":{"id":"I6RlVJhM4eLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def matricule_read_tun(cropped_plate, reader):\n","\n","    # Step 1: Upscale the image\n","    scale_factor = 2\n","    new_width = int(cropped_plate.shape[1] * scale_factor)\n","    new_height = int(cropped_plate.shape[0] * scale_factor)\n","    upscaled_image = cv2.resize(cropped_plate, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n","\n","    # Step 2: Define cropping areas (removing the middle part)\n","    image_height, image_width = upscaled_image.shape[:2]\n","    middle_start = int(image_width * 0.4)\n","    middle_end = int(image_width * 0.6)\n","\n","    left_part = upscaled_image[:, :middle_start]  # Left part\n","    right_part = upscaled_image[:, middle_end:]   # Right part\n","\n","    # Convert to grayscale\n","    left_gray = cv2.cvtColor(left_part, cv2.COLOR_BGR2GRAY)\n","    right_gray = cv2.cvtColor(right_part, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Gaussian blur\n","    left_blurred = cv2.GaussianBlur(left_gray, (5, 5), 0)\n","    right_blurred = cv2.GaussianBlur(right_gray, (5, 5), 0)\n","\n","    # Variables to store the best results for left and right parts\n","    best_confidence_left = 0\n","    best_confidence_right = 0\n","    best_result_left = None\n","    best_result_right = None\n","\n","    # Iterate over threshold values\n","    for threshold_value in range(30, 200, 5):\n","        _, left_threshold = cv2.threshold(left_blurred, threshold_value, 255, cv2.THRESH_BINARY)\n","        _, right_threshold = cv2.threshold(right_blurred, threshold_value, 255, cv2.THRESH_BINARY)\n","\n","        # Perform OCR\n","        left_result = [res for res in reader.readtext(left_threshold) if res[1].isdigit()]\n","        right_result = [res for res in reader.readtext(right_threshold) if res[1].isdigit()]\n","\n","        # Calculate confidence for left and right results\n","        confidence_left = sum(item[2] for item in left_result) / len(left_result) if left_result else 0\n","        confidence_right = sum(item[2] for item in right_result) / len(right_result) if right_result else 0\n","\n","        # Update the best result for left part\n","        if confidence_left > best_confidence_left:\n","            best_confidence_left = confidence_left\n","            best_result_left = left_result\n","\n","        # Update the best result for right part\n","        if confidence_right > best_confidence_right:\n","            best_confidence_right = confidence_right\n","            best_result_right = right_result\n","\n","    # Extract the best numeric results\n","    left_number = int(best_result_left[0][1]) if best_result_left else None\n","    right_number = int(best_result_right[0][1]) if best_result_right else None\n","\n","    # Return the results as a dictionary\n","    return {\n","        \"left\": {\"number\": left_number, \"confidence\": best_confidence_left},\n","        \"right\": {\"number\": right_number, \"confidence\": best_confidence_right},\n","    }"],"metadata":{"id":"OHAjWCaf5cUB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def matricule_read_other(cropped_plate, reader):\n","\n","    # Step 1: Upscale the image\n","    scale_factor = 2\n","    new_width = int(cropped_plate.shape[1] * scale_factor)\n","    new_height = int(cropped_plate.shape[0] * scale_factor)\n","    upscaled_image = cv2.resize(cropped_plate, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n","\n","    # Convert to grayscale\n","    gray_image = cv2.cvtColor(upscaled_image, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Gaussian blur\n","    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n","\n","    # Variables to store the best result\n","    best_confidence = 0\n","    best_result = None\n","\n","    # Iterate over threshold values\n","    for threshold_value in range(30, 200, 5):\n","        _, thresholded_image = cv2.threshold(blurred_image, threshold_value, 255, cv2.THRESH_BINARY)\n","\n","        # Perform OCR\n","        results = [res for res in reader.readtext(thresholded_image) if res[1].isdigit()]\n","\n","        # Calculate confidence for the results\n","        if results:\n","            confidence = sum(item[2] for item in results) / len(results)\n","\n","            # Update the best result\n","            if confidence > best_confidence:\n","                best_confidence = confidence\n","                best_result = results\n","\n","    # Extract the best numeric result\n","    value = int(best_result[0][1]) if best_result else None\n","\n","    return {\"value\": value, \"confidence\": best_confidence}\n"],"metadata":{"id":"R4sGfaLJ5duT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def licensetype(image_array, modelcustom):\n","    # Resize the image to (128, 128) and convert it to grayscale\n","    image_size = (128, 128)\n","    img = array_to_img(image_array)  # Convert NumPy array to PIL Image\n","    img = img.resize(image_size).convert(\"L\")  # Resize and convert to grayscale\n","\n","    # Preprocess the image\n","    img_array = img_to_array(img)  # Convert image to array\n","    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","    img_array = img_array / 255.0  # Normalize the image (same as training)\n","\n","    # Make a prediction\n","    prediction = modelcustom.predict(img_array)\n","\n","    # Output the result based on the threshold\n","    return 0 if prediction[0] > 0.5 else 1"],"metadata":{"id":"jxGAfNRe5e7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gX-8qPM3EQT","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"613cf80f-ae97-4165-8623-a1d9c799456e","collapsed":true,"executionInfo":{"status":"error","timestamp":1734449872392,"user_tz":-60,"elapsed":937,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'FPS' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-b14dcd50e398>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframe_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mframe_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtime_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mFPS\u001b[0m  \u001b[0;31m# Time interval per frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Model inference for vehicle detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'FPS' is not defined"]}],"source":["# Process video frames\n","with sv.VideoSink(OUTPUT_VIDEO_PATH, video_info) as sink:\n","    frame_count = 0\n","    for frame in frame_generator:\n","        frame_count += 1\n","        # Model inference for vehicle detection\n","        result = model(frame)[0]\n","        detections = sv.Detections.from_ultralytics(result)\n","\n","        # Filter detections by confidence threshold\n","        detections = detections[detections.confidence > CONFIDENCE_THRESHOLD]\n","\n","        # Trigger zone filter\n","        detections = detections[polygon_zone.trigger(detections)]\n","\n","        # Apply Non-Maximum Suppression (NMS)\n","        detections = detections.with_nms(threshold=IOU_THRESHOLD)\n","\n","        # Update tracker\n","        detections = byte_track.update_with_detections(detections=detections)\n","\n","        # Transform tracking points\n","        points = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n","        points = view_transformer.transform_points(points=points).astype(int)\n","\n","        for tracker_id, [_, y] in zip(detections.tracker_id, points):\n","            coordinates[tracker_id].append(y)\n","\n","        # Start frame annotation\n","        annotated_frame = frame.copy()\n","\n","        # License plate detection and annotation\n","        if detections.xyxy is not None and len(detections.xyxy) > 0:\n","            for i, bbox in enumerate(detections.xyxy):\n","                # Car bounding box coordinates\n","                x1, y1, x2, y2 = map(int, bbox)\n","                cropped_car = frame[y1:y2, x1:x2]  # Crop car from frame\n","\n","                # Ensure cropped car is valid\n","                if cropped_car.size == 0:\n","                    continue\n","\n","                # Detect license plates within the cropped car\n","                result = matricule(cropped_car)\n","                if result and \"predictions\" in result:\n","                    # Initialize a dictionary to track best confidence and corresponding values for each license plate\n","                    plate_results = {}\n","                    predictions = result[\"predictions\"]\n","                    for prediction in predictions:\n","                        # License plate bounding box (relative to cropped_car)\n","                        lx, ly, lwidth, lheight = (\n","                            prediction[\"x\"],\n","                            prediction[\"y\"],\n","                            prediction[\"width\"],\n","                            prediction[\"height\"],\n","                        )\n","\n","                        # Convert center-based box to corner-based coordinates\n","                        lleft = int(lx - lwidth / 2)\n","                        ltop = int(ly - lheight / 2)\n","                        lright = int(lx + lwidth / 2)\n","                        lbottom = int(ly + lheight / 2)\n","\n","                        # Adjust to global frame coordinates\n","                        plate_left = lleft + x1\n","                        plate_top = ltop + y1\n","                        plate_right = lright + x1\n","                        plate_bottom = lbottom + y1\n","\n","                        # Crop license plate from the frame\n","                        cropped_plate = frame[plate_top:plate_bottom, plate_left:plate_right]\n","\n","                        # Validate cropped license plate\n","                        if cropped_plate.size == 0:\n","                            continue\n","\n","                        # Process every 15th frame\n","                        if frame_count % 15 == 0:\n","\n","                            # Pass the buffer to the licensetype function\n","                            license_type = licensetype(cropped_plate, modelcustom)  # Determine license type\n","\n","                            if license_type == 0:  # Tunisian plates\n","                                read_result = matricule_read_tun(cropped_plate,reader)\n","                                if read_result:\n","                                    left_number = read_result.get(\"left_number\", \"Unknown\")\n","                                    right_number = read_result.get(\"right_number\", \"Unknown\")\n","                                    label = f\"{left_number}تونس{right_number}\"\n","                                    confidence = read_result.get(\"confidence\", 0.0)\n","\n","                            else:  # Other plates\n","                                read_result = matricule_read_other(cropped_plate,reader)\n","                                if read_result:\n","                                    plate_value = read_result.get(\"value\", \"Unknown\")\n","                                    label = f\"value: {plate_value}\"\n","                                    confidence = read_result.get(\"confidence\", 0.0)\n","\n","                            # Update the best confidence value for the plate\n","                            plate_key = (plate_left, plate_top, plate_right, plate_bottom)\n","                            if (\n","                                plate_key not in plate_results\n","                                or confidence > plate_results[plate_key][\"confidence\"]\n","                            ):\n","                                plate_results[plate_key] = {\n","                                    \"label\": label,\n","                                    \"confidence\": confidence,\n","                                }\n","\n","                        # Annotate license plate on the frame\n","                        plate_label = plate_results.get(\n","                            (plate_left, plate_top, plate_right, plate_bottom), {}\n","                        ).get(\"label\", \"Unknown\")\n","                        license_plate_detections = sv.Detections(\n","                            xyxy=np.array([[plate_left, plate_top, plate_right, plate_bottom]]),\n","                            confidence=np.array([1.0]),  # Assign confidence for annotation\n","                            class_id=np.array([0]),  # Assign a class ID for license plates\n","                        )\n","\n","                        # Draw bounding boxes\n","                        annotated_frame = box_annotator.annotate(\n","                            scene=annotated_frame,\n","                            detections=license_plate_detections,\n","                        )\n","\n","                        # Overlay the label text above the bounding box\n","                        cv2.putText(\n","                            annotated_frame,\n","                            plate_label,\n","                            (plate_left, plate_top - 10),  # Position text above the bounding box\n","                            cv2.FONT_HERSHEY_SIMPLEX,\n","                            0.5,  # Font scale\n","                            (255, 0, 0),  # Font color (blue in BGR)\n","                            2,  # Thickness\n","                            cv2.LINE_AA,\n","                        )\n","\n","        # Write annotated frame to output video\n","        sink.write_frame(annotated_frame)"]},{"cell_type":"code","source":["plate_results = {}\n","coordinates = {}\n","speed_data = {}  # To store car tracking and speed\n","\n","# Process video frames\n","with sv.VideoSink(OUTPUT_VIDEO_PATH, video_info) as sink:\n","    frame_count = 0\n","    for frame in frame_generator:\n","        frame_count += 1\n","\n","        # Model inference for vehicle detection\n","        result = model(frame)[0]\n","        detections = sv.Detections.from_ultralytics(result)\n","\n","        # Filter detections by confidence threshold\n","        detections = detections[detections.confidence > CONFIDENCE_THRESHOLD]\n","\n","        # Trigger zone filter\n","        detections = detections[polygon_zone.trigger(detections)]\n","\n","        # Apply Non-Maximum Suppression (NMS)\n","        detections = detections.with_nms(threshold=IOU_THRESHOLD)\n","\n","        # Update tracker\n","        detections = byte_track.update_with_detections(detections=detections)\n","\n","        # Transform tracking points\n","        points = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n","        points = view_transformer.transform_points(points=points).astype(int)\n","\n","        for tracker_id, [_, y] in zip(detections.tracker_id, points):\n","            if tracker_id not in coordinates:\n","                coordinates[tracker_id] = []\n","            coordinates[tracker_id].append(y)\n","\n","            # Calculate speed based on change in y-coordinate over frames\n","            if len(coordinates[tracker_id]) > 1:\n","                previous_y = coordinates[tracker_id][-2]\n","                current_y = y\n","                speed = abs(current_y - previous_y) * 0.5  # Simplified speed calculation\n","                speed_data[tracker_id] = speed\n","\n","        # Start frame annotation\n","        annotated_frame = frame.copy()\n","\n","        # License plate detection and annotation\n","        if detections.xyxy is not None and len(detections.xyxy) > 0:\n","            for i, bbox in enumerate(detections.xyxy):\n","                # Car bounding box coordinates\n","                x1, y1, x2, y2 = map(int, bbox)\n","                cropped_car = frame[y1:y2, x1:x2]  # Crop car from frame\n","\n","                # Ensure cropped car is valid\n","                if cropped_car.size == 0:\n","                    continue\n","\n","                # Detect license plates within the cropped car\n","                result = matricule(cropped_car)\n","                if result and \"predictions\" in result:\n","                    predictions = result[\"predictions\"]\n","                    for prediction in predictions:\n","                        # License plate bounding box\n","                        lx, ly, lwidth, lheight = (\n","                            prediction[\"x\"],\n","                            prediction[\"y\"],\n","                            prediction[\"width\"],\n","                            prediction[\"height\"],\n","                        )\n","                        lleft = int(lx - lwidth / 2)\n","                        ltop = int(ly - lheight / 2)\n","                        lright = int(lx + lwidth / 2)\n","                        lbottom = int(ly + lheight / 2)\n","\n","                        # Adjust to global frame coordinates\n","                        plate_left = lleft + x1\n","                        plate_top = ltop + y1\n","                        plate_right = lright + x1\n","                        plate_bottom = lbottom + y1\n","\n","                        cropped_plate = frame[plate_top:plate_bottom, plate_left:plate_right]\n","                        if cropped_plate.size == 0:\n","                            continue\n","\n","                        if frame_count % 15 == 0:\n","                            # Pass cropped plate to recognition functions\n","                            license_type = licensetype(cropped_plate, modelcustom)\n","                            if license_type == 0:  # Tunisian plates\n","                                read_result = matricule_read_tun(cropped_plate, reader)\n","                                if read_result:\n","                                    left_number = read_result.get(\"left_number\", \"Unknown\")\n","                                    right_number = read_result.get(\"right_number\", \"Unknown\")\n","                                    label = f\"{left_number}تونس{right_number}\"\n","                                    confidence = read_result.get(\"confidence\", 0.0)\n","                            else:  # Other plates\n","                                read_result = matricule_read_other(cropped_plate, reader)\n","                                if read_result:\n","                                    plate_value = read_result.get(\"value\", \"Unknown\")\n","                                    label = f\"value: {plate_value}\"\n","                                    confidence = read_result.get(\"confidence\", 0.0)\n","\n","                            plate_key = (plate_left, plate_top, plate_right, plate_bottom)\n","                            if (\n","                                plate_key not in plate_results\n","                                or confidence > plate_results[plate_key][\"confidence\"]\n","                            ):\n","                                plate_results[plate_key] = {\n","                                    \"label\": label,\n","                                    \"confidence\": confidence,\n","                                }\n","\n","                        # Annotate car with speed and license plate\n","                        car_speed = speed_data.get(detections.tracker_id[i], 0.0)\n","                        plate_label = plate_results.get(\n","                            (plate_left, plate_top, plate_right, plate_bottom), {}\n","                        ).get(\"label\", \"Unknown\")\n","\n","                        full_label = f\"ID: {detections.tracker_id[i]} | Speed: {car_speed:.2f} px/frame | {plate_label}\"\n","\n","                        license_plate_detections = sv.Detections(\n","                            xyxy=np.array([[plate_left, plate_top, plate_right, plate_bottom]]),\n","                            confidence=np.array([1.0]),\n","                            class_id=np.array([0]),\n","                        )\n","\n","                        # Draw bounding boxes and labels\n","                        annotated_frame = box_annotator.annotate(\n","                            scene=annotated_frame,\n","                            detections=license_plate_detections,\n","                        )\n","                        cv2.putText(\n","                            annotated_frame,\n","                            full_label,\n","                            (plate_left, plate_top - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX,\n","                            0.5,\n","                            (0, 255, 0),  # Green for text\n","                            2,\n","                            cv2.LINE_AA,\n","                        )\n","\n","        # Write annotated frame to output video\n","        sink.write_frame(annotated_frame)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xrx5vW2qQi1d","outputId":"50a8bde3-0ba0-4e00-8091-6165bf76894a","executionInfo":{"status":"ok","timestamp":1734450799595,"user_tz":-60,"elapsed":581787,"user":{"displayName":"Basilisk ツ","userId":"06197885570782553589"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 4 cars, 2 trucks, 201.9ms\n","Speed: 6.1ms preprocess, 201.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 190.3ms\n","Speed: 10.5ms preprocess, 190.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 181.2ms\n","Speed: 6.6ms preprocess, 181.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 163.3ms\n","Speed: 8.7ms preprocess, 163.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 170.3ms\n","Speed: 4.6ms preprocess, 170.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 2 trucks, 183.4ms\n","Speed: 6.0ms preprocess, 183.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 176.6ms\n","Speed: 4.6ms preprocess, 176.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 259.0ms\n","Speed: 6.9ms preprocess, 259.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 171.2ms\n","Speed: 5.4ms preprocess, 171.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 171.6ms\n","Speed: 4.8ms preprocess, 171.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 1 truck, 185.2ms\n","Speed: 7.7ms preprocess, 185.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 2 trucks, 163.4ms\n","Speed: 5.1ms preprocess, 163.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 184.0ms\n","Speed: 12.2ms preprocess, 184.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 275.0ms\n","Speed: 10.8ms preprocess, 275.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 1 truck, 266.0ms\n","Speed: 6.5ms preprocess, 266.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\n","0: 384x640 4 cars, 1 truck, 158.6ms\n","Speed: 5.6ms preprocess, 158.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 1 truck, 178.8ms\n","Speed: 4.2ms preprocess, 178.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 2 trucks, 171.2ms\n","Speed: 9.3ms preprocess, 171.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 2 trucks, 196.9ms\n","Speed: 5.2ms preprocess, 196.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 264.7ms\n","Speed: 7.6ms preprocess, 264.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 171.2ms\n","Speed: 5.6ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 166.6ms\n","Speed: 4.2ms preprocess, 166.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 180.7ms\n","Speed: 6.2ms preprocess, 180.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 161.8ms\n","Speed: 6.4ms preprocess, 161.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 164.3ms\n","Speed: 4.7ms preprocess, 164.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.6ms\n","Speed: 4.2ms preprocess, 167.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 189.5ms\n","Speed: 4.1ms preprocess, 189.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 253.4ms\n","Speed: 4.2ms preprocess, 253.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 248.9ms\n","Speed: 11.4ms preprocess, 248.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 285.3ms\n","Speed: 4.1ms preprocess, 285.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 3 cars, 185.7ms\n","Speed: 6.2ms preprocess, 185.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 225.4ms\n","Speed: 4.1ms preprocess, 225.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 264.9ms\n","Speed: 6.7ms preprocess, 264.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 162.3ms\n","Speed: 5.2ms preprocess, 162.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 184.1ms\n","Speed: 4.1ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 177.0ms\n","Speed: 4.7ms preprocess, 177.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 165.9ms\n","Speed: 4.2ms preprocess, 165.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 170.3ms\n","Speed: 4.2ms preprocess, 170.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 188.8ms\n","Speed: 11.0ms preprocess, 188.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 bench, 177.1ms\n","Speed: 4.5ms preprocess, 177.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 bench, 187.3ms\n","Speed: 5.0ms preprocess, 187.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 bench, 165.1ms\n","Speed: 10.3ms preprocess, 165.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 270.5ms\n","Speed: 4.3ms preprocess, 270.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 285.8ms\n","Speed: 6.4ms preprocess, 285.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 273.6ms\n","Speed: 4.2ms preprocess, 273.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 3 cars, 167.5ms\n","Speed: 4.5ms preprocess, 167.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 187.9ms\n","Speed: 7.9ms preprocess, 187.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 190.8ms\n","Speed: 4.1ms preprocess, 190.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 171.8ms\n","Speed: 3.9ms preprocess, 171.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 162.6ms\n","Speed: 4.0ms preprocess, 162.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 215.2ms\n","Speed: 5.4ms preprocess, 215.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 171.7ms\n","Speed: 4.3ms preprocess, 171.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 166.9ms\n","Speed: 4.4ms preprocess, 166.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 245.8ms\n","Speed: 6.7ms preprocess, 245.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 311.6ms\n","Speed: 7.4ms preprocess, 311.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 220.5ms\n","Speed: 4.2ms preprocess, 220.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 168.6ms\n","Speed: 5.0ms preprocess, 168.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 169.1ms\n","Speed: 4.6ms preprocess, 169.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 205.3ms\n","Speed: 4.9ms preprocess, 205.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 173.7ms\n","Speed: 6.0ms preprocess, 173.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\n","0: 384x640 3 cars, 174.5ms\n","Speed: 6.3ms preprocess, 174.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 198.5ms\n","Speed: 4.0ms preprocess, 198.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 273.9ms\n","Speed: 4.8ms preprocess, 273.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 296.3ms\n","Speed: 4.0ms preprocess, 296.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 270.3ms\n","Speed: 5.0ms preprocess, 270.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 170.6ms\n","Speed: 4.2ms preprocess, 170.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 179.0ms\n","Speed: 4.0ms preprocess, 179.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 168.1ms\n","Speed: 5.2ms preprocess, 168.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 177.6ms\n","Speed: 4.7ms preprocess, 177.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 173.8ms\n","Speed: 5.1ms preprocess, 173.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 178.8ms\n","Speed: 4.2ms preprocess, 178.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 182.8ms\n","Speed: 4.3ms preprocess, 182.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 160.2ms\n","Speed: 3.8ms preprocess, 160.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 169.6ms\n","Speed: 4.0ms preprocess, 169.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 195.7ms\n","Speed: 6.8ms preprocess, 195.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\n","0: 384x640 3 cars, 203.3ms\n","Speed: 6.3ms preprocess, 203.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 165.5ms\n","Speed: 4.2ms preprocess, 165.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 162.7ms\n","Speed: 4.2ms preprocess, 162.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 178.7ms\n","Speed: 4.5ms preprocess, 178.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 168.2ms\n","Speed: 5.0ms preprocess, 168.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 166.4ms\n","Speed: 4.7ms preprocess, 166.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 169.0ms\n","Speed: 4.6ms preprocess, 169.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 180.4ms\n","Speed: 4.3ms preprocess, 180.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 173.9ms\n","Speed: 4.1ms preprocess, 173.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 276.3ms\n","Speed: 6.8ms preprocess, 276.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 298.4ms\n","Speed: 5.1ms preprocess, 298.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 175.8ms\n","Speed: 4.3ms preprocess, 175.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 167.7ms\n","Speed: 4.7ms preprocess, 167.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 168.7ms\n","Speed: 6.4ms preprocess, 168.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 159.3ms\n","Speed: 4.2ms preprocess, 159.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 3 cars, 267.2ms\n","Speed: 4.0ms preprocess, 267.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 170.3ms\n","Speed: 6.2ms preprocess, 170.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 168.1ms\n","Speed: 4.1ms preprocess, 168.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 162.0ms\n","Speed: 5.8ms preprocess, 162.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 182.7ms\n","Speed: 5.7ms preprocess, 182.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 176.9ms\n","Speed: 4.1ms preprocess, 176.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 157.1ms\n","Speed: 9.5ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 161.6ms\n","Speed: 4.3ms preprocess, 161.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 176.8ms\n","Speed: 4.8ms preprocess, 176.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 287.1ms\n","Speed: 9.6ms preprocess, 287.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 190.0ms\n","Speed: 4.0ms preprocess, 190.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 167.8ms\n","Speed: 4.7ms preprocess, 167.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 187.0ms\n","Speed: 6.5ms preprocess, 187.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 176.4ms\n","Speed: 8.0ms preprocess, 176.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 155.9ms\n","Speed: 5.0ms preprocess, 155.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\n","0: 384x640 3 cars, 162.4ms\n","Speed: 4.6ms preprocess, 162.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 190.5ms\n","Speed: 5.2ms preprocess, 190.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 169.6ms\n","Speed: 4.5ms preprocess, 169.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 196.7ms\n","Speed: 4.7ms preprocess, 196.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 171.0ms\n","Speed: 5.4ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 176.4ms\n","Speed: 5.0ms preprocess, 176.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 167.2ms\n","Speed: 3.9ms preprocess, 167.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 241.0ms\n","Speed: 13.1ms preprocess, 241.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 240.8ms\n","Speed: 12.4ms preprocess, 240.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 298.5ms\n","Speed: 13.5ms preprocess, 298.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 175.5ms\n","Speed: 7.5ms preprocess, 175.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 174.2ms\n","Speed: 4.9ms preprocess, 174.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 162.5ms\n","Speed: 5.5ms preprocess, 162.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 199.8ms\n","Speed: 4.4ms preprocess, 199.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 173.2ms\n","Speed: 4.9ms preprocess, 173.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 2 cars, 1 truck, 168.4ms\n","Speed: 6.3ms preprocess, 168.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 176.3ms\n","Speed: 4.0ms preprocess, 176.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 179.2ms\n","Speed: 4.5ms preprocess, 179.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 300.2ms\n","Speed: 4.4ms preprocess, 300.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 268.0ms\n","Speed: 8.4ms preprocess, 268.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 299.3ms\n","Speed: 4.1ms preprocess, 299.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 290.0ms\n","Speed: 4.4ms preprocess, 290.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 184.0ms\n","Speed: 4.2ms preprocess, 184.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 177.1ms\n","Speed: 4.2ms preprocess, 177.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 160.7ms\n","Speed: 4.4ms preprocess, 160.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 179.5ms\n","Speed: 4.3ms preprocess, 179.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 188.0ms\n","Speed: 4.4ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 196.9ms\n","Speed: 4.2ms preprocess, 196.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 174.4ms\n","Speed: 5.0ms preprocess, 174.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 188.5ms\n","Speed: 9.9ms preprocess, 188.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\n","0: 384x640 2 cars, 181.4ms\n","Speed: 6.9ms preprocess, 181.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 271.0ms\n","Speed: 10.6ms preprocess, 271.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 247.0ms\n","Speed: 7.6ms preprocess, 247.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 314.0ms\n","Speed: 6.5ms preprocess, 314.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 209.0ms\n","Speed: 11.9ms preprocess, 209.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 192.6ms\n","Speed: 4.8ms preprocess, 192.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 171.3ms\n","Speed: 4.4ms preprocess, 171.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 196.6ms\n","Speed: 4.5ms preprocess, 196.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 181.0ms\n","Speed: 5.6ms preprocess, 181.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 168.4ms\n","Speed: 5.1ms preprocess, 168.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 180.8ms\n","Speed: 5.3ms preprocess, 180.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 191.1ms\n","Speed: 4.4ms preprocess, 191.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 172.5ms\n","Speed: 6.9ms preprocess, 172.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.6ms\n","Speed: 3.9ms preprocess, 174.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 165.4ms\n","Speed: 4.0ms preprocess, 165.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\n","0: 384x640 3 cars, 1 truck, 307.1ms\n","Speed: 6.8ms preprocess, 307.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 266.8ms\n","Speed: 4.7ms preprocess, 266.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 161.5ms\n","Speed: 4.2ms preprocess, 161.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 177.2ms\n","Speed: 4.3ms preprocess, 177.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 198.8ms\n","Speed: 7.3ms preprocess, 198.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 171.5ms\n","Speed: 4.2ms preprocess, 171.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 173.3ms\n","Speed: 4.6ms preprocess, 173.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 191.0ms\n","Speed: 4.1ms preprocess, 191.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 180.8ms\n","Speed: 5.2ms preprocess, 180.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 184.8ms\n","Speed: 5.2ms preprocess, 184.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 159.4ms\n","Speed: 4.5ms preprocess, 159.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 185.7ms\n","Speed: 4.3ms preprocess, 185.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 182.4ms\n","Speed: 4.7ms preprocess, 182.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 169.5ms\n","Speed: 6.6ms preprocess, 169.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 168.5ms\n","Speed: 10.6ms preprocess, 168.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","\n","0: 384x640 2 cars, 284.8ms\n","Speed: 6.8ms preprocess, 284.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 304.4ms\n","Speed: 8.6ms preprocess, 304.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 171.1ms\n","Speed: 4.2ms preprocess, 171.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 181.5ms\n","Speed: 4.5ms preprocess, 181.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.6ms\n","Speed: 7.4ms preprocess, 167.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 193.7ms\n","Speed: 9.2ms preprocess, 193.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 170.6ms\n","Speed: 4.5ms preprocess, 170.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 171.7ms\n","Speed: 4.8ms preprocess, 171.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 179.6ms\n","Speed: 4.8ms preprocess, 179.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.7ms\n","Speed: 5.3ms preprocess, 174.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 182.6ms\n","Speed: 6.3ms preprocess, 182.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 159.7ms\n","Speed: 4.3ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 167.7ms\n","Speed: 7.9ms preprocess, 167.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 193.9ms\n","Speed: 5.5ms preprocess, 193.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 194.1ms\n","Speed: 7.4ms preprocess, 194.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\n","0: 384x640 3 cars, 1 truck, 169.5ms\n","Speed: 6.0ms preprocess, 169.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 177.9ms\n","Speed: 4.1ms preprocess, 177.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 176.7ms\n","Speed: 5.6ms preprocess, 176.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 172.3ms\n","Speed: 6.0ms preprocess, 172.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 197.7ms\n","Speed: 5.3ms preprocess, 197.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 182.0ms\n","Speed: 6.5ms preprocess, 182.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 178.9ms\n","Speed: 4.2ms preprocess, 178.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 168.5ms\n","Speed: 4.7ms preprocess, 168.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 204.0ms\n","Speed: 4.9ms preprocess, 204.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 180.6ms\n","Speed: 4.1ms preprocess, 180.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 164.5ms\n","Speed: 5.6ms preprocess, 164.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.0ms\n","Speed: 4.3ms preprocess, 174.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 186.4ms\n","Speed: 5.2ms preprocess, 186.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 185.4ms\n","Speed: 4.5ms preprocess, 185.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 170.5ms\n","Speed: 4.7ms preprocess, 170.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 2 cars, 1 truck, 185.9ms\n","Speed: 4.2ms preprocess, 185.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 188.1ms\n","Speed: 4.4ms preprocess, 188.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 177.6ms\n","Speed: 6.7ms preprocess, 177.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 1 truck, 171.0ms\n","Speed: 4.6ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 164.1ms\n","Speed: 5.5ms preprocess, 164.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 175.7ms\n","Speed: 4.2ms preprocess, 175.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 172.1ms\n","Speed: 4.1ms preprocess, 172.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 166.0ms\n","Speed: 4.0ms preprocess, 166.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 337.0ms\n","Speed: 5.2ms preprocess, 337.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 315.8ms\n","Speed: 5.8ms preprocess, 315.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 294.7ms\n","Speed: 7.4ms preprocess, 294.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 165.3ms\n","Speed: 4.1ms preprocess, 165.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.7ms\n","Speed: 5.6ms preprocess, 167.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 182.7ms\n","Speed: 5.8ms preprocess, 182.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 178.3ms\n","Speed: 4.4ms preprocess, 178.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 168.8ms\n","Speed: 4.2ms preprocess, 168.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 161.0ms\n","Speed: 4.3ms preprocess, 161.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 180.9ms\n","Speed: 4.5ms preprocess, 180.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 189.0ms\n","Speed: 4.4ms preprocess, 189.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 183.1ms\n","Speed: 5.1ms preprocess, 183.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 176.3ms\n","Speed: 4.4ms preprocess, 176.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 213.3ms\n","Speed: 5.0ms preprocess, 213.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 191.4ms\n","Speed: 5.6ms preprocess, 191.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 truck, 155.8ms\n","Speed: 5.3ms preprocess, 155.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 168.1ms\n","Speed: 4.4ms preprocess, 168.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 196.6ms\n","Speed: 4.3ms preprocess, 196.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 train, 1 truck, 170.9ms\n","Speed: 8.4ms preprocess, 170.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 train, 1 truck, 164.8ms\n","Speed: 4.5ms preprocess, 164.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 190.0ms\n","Speed: 5.8ms preprocess, 190.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 201.7ms\n","Speed: 4.3ms preprocess, 201.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 171.8ms\n","Speed: 4.6ms preprocess, 171.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 161.3ms\n","Speed: 5.5ms preprocess, 161.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 173.2ms\n","Speed: 5.0ms preprocess, 173.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 188.6ms\n","Speed: 6.8ms preprocess, 188.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 1 truck, 176.0ms\n","Speed: 5.0ms preprocess, 176.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 167.3ms\n","Speed: 8.4ms preprocess, 167.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 274.2ms\n","Speed: 7.9ms preprocess, 274.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 1 truck, 289.3ms\n","Speed: 8.0ms preprocess, 289.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 1 truck, 280.9ms\n","Speed: 7.4ms preprocess, 280.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 205.5ms\n","Speed: 7.1ms preprocess, 205.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 179.4ms\n","Speed: 7.4ms preprocess, 179.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 187.7ms\n","Speed: 5.2ms preprocess, 187.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 175.0ms\n","Speed: 7.3ms preprocess, 175.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 173.6ms\n","Speed: 4.2ms preprocess, 173.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 167.0ms\n","Speed: 5.5ms preprocess, 167.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\n","0: 384x640 1 car, 187.0ms\n","Speed: 4.4ms preprocess, 187.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 189.2ms\n","Speed: 5.0ms preprocess, 189.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 165.7ms\n","Speed: 4.5ms preprocess, 165.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 180.4ms\n","Speed: 7.2ms preprocess, 180.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 189.0ms\n","Speed: 4.2ms preprocess, 189.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 175.5ms\n","Speed: 3.9ms preprocess, 175.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 train, 1 truck, 165.5ms\n","Speed: 5.7ms preprocess, 165.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 185.1ms\n","Speed: 4.1ms preprocess, 185.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 252.2ms\n","Speed: 11.2ms preprocess, 252.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 269.2ms\n","Speed: 10.4ms preprocess, 269.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 267.9ms\n","Speed: 4.9ms preprocess, 267.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 168.3ms\n","Speed: 5.0ms preprocess, 168.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 195.2ms\n","Speed: 5.1ms preprocess, 195.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 167.5ms\n","Speed: 4.1ms preprocess, 167.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 178.1ms\n","Speed: 4.1ms preprocess, 178.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\n","0: 384x640 1 car, 1 truck, 160.9ms\n","Speed: 4.7ms preprocess, 160.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 189.6ms\n","Speed: 5.8ms preprocess, 189.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 190.9ms\n","Speed: 6.3ms preprocess, 190.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 194.6ms\n","Speed: 4.6ms preprocess, 194.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 174.2ms\n","Speed: 5.7ms preprocess, 174.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 208.2ms\n","Speed: 4.9ms preprocess, 208.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 189.7ms\n","Speed: 5.4ms preprocess, 189.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 173.1ms\n","Speed: 4.9ms preprocess, 173.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 184.4ms\n","Speed: 5.7ms preprocess, 184.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 246.3ms\n","Speed: 4.1ms preprocess, 246.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 271.4ms\n","Speed: 4.2ms preprocess, 271.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 257.0ms\n","Speed: 4.4ms preprocess, 257.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 301.0ms\n","Speed: 4.3ms preprocess, 301.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 350.2ms\n","Speed: 8.0ms preprocess, 350.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 241.9ms\n","Speed: 4.9ms preprocess, 241.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\n","0: 384x640 1 car, 1 bus, 158.8ms\n","Speed: 4.0ms preprocess, 158.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 161.1ms\n","Speed: 4.6ms preprocess, 161.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 207.8ms\n","Speed: 5.2ms preprocess, 207.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 185.2ms\n","Speed: 4.6ms preprocess, 185.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 168.2ms\n","Speed: 4.5ms preprocess, 168.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 195.6ms\n","Speed: 6.1ms preprocess, 195.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 328.1ms\n","Speed: 9.2ms preprocess, 328.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 272.2ms\n","Speed: 6.2ms preprocess, 272.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 182.2ms\n","Speed: 4.1ms preprocess, 182.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 167.6ms\n","Speed: 4.0ms preprocess, 167.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 203.3ms\n","Speed: 4.0ms preprocess, 203.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 168.6ms\n","Speed: 5.4ms preprocess, 168.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 171.6ms\n","Speed: 7.2ms preprocess, 171.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 169.0ms\n","Speed: 4.3ms preprocess, 169.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 183.8ms\n","Speed: 5.0ms preprocess, 183.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 282.1ms\n","Speed: 4.3ms preprocess, 282.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 266.3ms\n","Speed: 4.6ms preprocess, 266.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 166.8ms\n","Speed: 7.7ms preprocess, 166.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 184.7ms\n","Speed: 8.2ms preprocess, 184.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 180.1ms\n","Speed: 7.4ms preprocess, 180.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 165.4ms\n","Speed: 5.1ms preprocess, 165.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 182.7ms\n","Speed: 6.2ms preprocess, 182.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 219.7ms\n","Speed: 10.1ms preprocess, 219.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 166.2ms\n","Speed: 11.5ms preprocess, 166.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 183.2ms\n","Speed: 4.3ms preprocess, 183.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 1 truck, 154.8ms\n","Speed: 4.2ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 195.4ms\n","Speed: 5.3ms preprocess, 195.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 1 truck, 210.9ms\n","Speed: 6.0ms preprocess, 210.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 174.8ms\n","Speed: 4.4ms preprocess, 174.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 218.3ms\n","Speed: 4.8ms preprocess, 218.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 184.3ms\n","Speed: 5.5ms preprocess, 184.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 train, 175.3ms\n","Speed: 4.1ms preprocess, 175.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 167.9ms\n","Speed: 9.4ms preprocess, 167.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 163.6ms\n","Speed: 4.5ms preprocess, 163.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 train, 182.1ms\n","Speed: 4.0ms preprocess, 182.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 174.7ms\n","Speed: 7.9ms preprocess, 174.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 172.0ms\n","Speed: 4.3ms preprocess, 172.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 162.2ms\n","Speed: 4.3ms preprocess, 162.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 186.0ms\n","Speed: 5.0ms preprocess, 186.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 183.3ms\n","Speed: 5.1ms preprocess, 183.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 169.9ms\n","Speed: 4.5ms preprocess, 169.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 242.5ms\n","Speed: 4.0ms preprocess, 242.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 287.4ms\n","Speed: 4.8ms preprocess, 287.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 277.7ms\n","Speed: 5.3ms preprocess, 277.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 bus, 1 truck, 186.0ms\n","Speed: 4.3ms preprocess, 186.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 1 car, 1 truck, 164.2ms\n","Speed: 8.1ms preprocess, 164.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 275.5ms\n","Speed: 5.0ms preprocess, 275.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 165.4ms\n","Speed: 4.3ms preprocess, 165.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 166.3ms\n","Speed: 4.4ms preprocess, 166.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 180.0ms\n","Speed: 4.1ms preprocess, 180.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 180.8ms\n","Speed: 5.0ms preprocess, 180.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 190.1ms\n","Speed: 7.3ms preprocess, 190.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 169.1ms\n","Speed: 4.5ms preprocess, 169.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 183.2ms\n","Speed: 4.0ms preprocess, 183.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 181.4ms\n","Speed: 6.6ms preprocess, 181.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 203.3ms\n","Speed: 4.4ms preprocess, 203.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 205.2ms\n","Speed: 5.8ms preprocess, 205.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 188.4ms\n","Speed: 4.3ms preprocess, 188.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 295.6ms\n","Speed: 4.1ms preprocess, 295.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 261.9ms\n","Speed: 7.4ms preprocess, 261.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 1 car, 1 truck, 257.5ms\n","Speed: 4.1ms preprocess, 257.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 197.2ms\n","Speed: 8.9ms preprocess, 197.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 194.9ms\n","Speed: 5.4ms preprocess, 194.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 170.8ms\n","Speed: 4.9ms preprocess, 170.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 174.7ms\n","Speed: 4.1ms preprocess, 174.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 178.1ms\n","Speed: 9.5ms preprocess, 178.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 195.5ms\n","Speed: 5.6ms preprocess, 195.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 163.4ms\n","Speed: 4.1ms preprocess, 163.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 185.8ms\n","Speed: 11.2ms preprocess, 185.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 171.3ms\n","Speed: 6.5ms preprocess, 171.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 285.2ms\n","Speed: 4.6ms preprocess, 285.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 290.7ms\n","Speed: 9.9ms preprocess, 290.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 219.0ms\n","Speed: 4.6ms preprocess, 219.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 194.0ms\n","Speed: 5.9ms preprocess, 194.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 178.3ms\n","Speed: 4.8ms preprocess, 178.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 2 cars, 1 truck, 165.1ms\n","Speed: 8.3ms preprocess, 165.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 220.5ms\n","Speed: 6.2ms preprocess, 220.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 275.1ms\n","Speed: 8.7ms preprocess, 275.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 190.6ms\n","Speed: 4.8ms preprocess, 190.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 171.9ms\n","Speed: 4.8ms preprocess, 171.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 167.9ms\n","Speed: 4.3ms preprocess, 167.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 195.4ms\n","Speed: 5.4ms preprocess, 195.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 180.1ms\n","Speed: 4.3ms preprocess, 180.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 1 truck, 167.6ms\n","Speed: 8.9ms preprocess, 167.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 cars, 1 truck, 245.3ms\n","Speed: 4.4ms preprocess, 245.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 255.2ms\n","Speed: 4.3ms preprocess, 255.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 329.4ms\n","Speed: 6.1ms preprocess, 329.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 178.6ms\n","Speed: 6.1ms preprocess, 178.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 178.8ms\n","Speed: 5.9ms preprocess, 178.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 164.3ms\n","Speed: 5.5ms preprocess, 164.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 2 cars, 2 trucks, 182.2ms\n","Speed: 4.3ms preprocess, 182.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.1ms\n","Speed: 4.5ms preprocess, 167.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 160.5ms\n","Speed: 9.1ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 175.5ms\n","Speed: 4.0ms preprocess, 175.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 184.7ms\n","Speed: 4.7ms preprocess, 184.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 160.3ms\n","Speed: 7.1ms preprocess, 160.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 2 trucks, 176.8ms\n","Speed: 6.2ms preprocess, 176.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 173.7ms\n","Speed: 4.3ms preprocess, 173.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 158.3ms\n","Speed: 4.2ms preprocess, 158.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 183.0ms\n","Speed: 4.0ms preprocess, 183.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 313.2ms\n","Speed: 4.4ms preprocess, 313.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 252.3ms\n","Speed: 8.3ms preprocess, 252.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 168.9ms\n","Speed: 7.8ms preprocess, 168.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 165.9ms\n","Speed: 4.8ms preprocess, 165.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 176.5ms\n","Speed: 9.0ms preprocess, 176.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\n","0: 384x640 2 cars, 1 truck, 168.6ms\n","Speed: 4.1ms preprocess, 168.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 2 trucks, 177.4ms\n","Speed: 9.2ms preprocess, 177.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 196.1ms\n","Speed: 6.3ms preprocess, 196.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 172.9ms\n","Speed: 4.3ms preprocess, 172.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 272.1ms\n","Speed: 6.4ms preprocess, 272.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 259.4ms\n","Speed: 8.0ms preprocess, 259.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 313.6ms\n","Speed: 4.2ms preprocess, 313.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 192.2ms\n","Speed: 5.7ms preprocess, 192.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 2 trucks, 176.3ms\n","Speed: 4.5ms preprocess, 176.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 163.7ms\n","Speed: 7.4ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 165.8ms\n","Speed: 7.1ms preprocess, 165.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 180.2ms\n","Speed: 4.8ms preprocess, 180.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 166.2ms\n","Speed: 5.9ms preprocess, 166.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 182.1ms\n","Speed: 4.0ms preprocess, 182.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 169.0ms\n","Speed: 5.9ms preprocess, 169.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 2 cars, 2 trucks, 184.4ms\n","Speed: 6.4ms preprocess, 184.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 2 trucks, 166.8ms\n","Speed: 6.0ms preprocess, 166.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 160.0ms\n","Speed: 10.3ms preprocess, 160.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 208.3ms\n","Speed: 7.2ms preprocess, 208.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 275.8ms\n","Speed: 7.9ms preprocess, 275.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 257.9ms\n","Speed: 10.9ms preprocess, 257.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 261.3ms\n","Speed: 4.5ms preprocess, 261.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 166.4ms\n","Speed: 4.6ms preprocess, 166.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 188.7ms\n","Speed: 4.1ms preprocess, 188.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.1ms\n","Speed: 4.3ms preprocess, 167.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 197.1ms\n","Speed: 5.0ms preprocess, 197.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 155.2ms\n","Speed: 8.9ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 180.6ms\n","Speed: 6.6ms preprocess, 180.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.8ms\n","Speed: 5.1ms preprocess, 174.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.7ms\n","Speed: 5.8ms preprocess, 167.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","0: 384x640 2 cars, 1 truck, 246.2ms\n","Speed: 6.8ms preprocess, 246.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 316.2ms\n","Speed: 10.0ms preprocess, 316.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 181.1ms\n","Speed: 5.5ms preprocess, 181.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.7ms\n","Speed: 9.6ms preprocess, 174.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 167.3ms\n","Speed: 8.3ms preprocess, 167.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.7ms\n","Speed: 5.5ms preprocess, 174.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 157.0ms\n","Speed: 4.5ms preprocess, 157.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 279.9ms\n","Speed: 7.1ms preprocess, 279.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 264.7ms\n","Speed: 7.2ms preprocess, 264.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 187.7ms\n","Speed: 6.4ms preprocess, 187.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 208.3ms\n","Speed: 6.6ms preprocess, 208.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 178.0ms\n","Speed: 7.0ms preprocess, 178.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 179.5ms\n","Speed: 8.4ms preprocess, 179.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 200.8ms\n","Speed: 5.1ms preprocess, 200.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 296.9ms\n","Speed: 4.4ms preprocess, 296.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","\n","0: 384x640 2 cars, 1 truck, 174.0ms\n","Speed: 4.4ms preprocess, 174.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 201.8ms\n","Speed: 6.2ms preprocess, 201.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 177.6ms\n","Speed: 8.3ms preprocess, 177.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 163.7ms\n","Speed: 4.2ms preprocess, 163.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 314.9ms\n","Speed: 6.8ms preprocess, 314.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 172.0ms\n","Speed: 4.2ms preprocess, 172.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 189.7ms\n","Speed: 6.1ms preprocess, 189.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 194.4ms\n","Speed: 5.2ms preprocess, 194.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 174.7ms\n","Speed: 4.2ms preprocess, 174.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 164.7ms\n","Speed: 4.3ms preprocess, 164.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 190.4ms\n","Speed: 5.2ms preprocess, 190.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 190.4ms\n","Speed: 5.2ms preprocess, 190.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 243.4ms\n","Speed: 6.4ms preprocess, 243.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 279.2ms\n","Speed: 4.2ms preprocess, 279.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 186.3ms\n","Speed: 4.5ms preprocess, 186.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","0: 384x640 2 cars, 1 truck, 166.9ms\n","Speed: 5.1ms preprocess, 166.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 172.2ms\n","Speed: 7.6ms preprocess, 172.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 260.7ms\n","Speed: 8.5ms preprocess, 260.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 296.9ms\n","Speed: 8.5ms preprocess, 296.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 182.7ms\n","Speed: 4.2ms preprocess, 182.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 165.8ms\n","Speed: 4.8ms preprocess, 165.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 433.8ms\n","Speed: 17.2ms preprocess, 433.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 216.4ms\n","Speed: 7.1ms preprocess, 216.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 200.3ms\n","Speed: 9.2ms preprocess, 200.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 259.0ms\n","Speed: 5.2ms preprocess, 259.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 197.7ms\n","Speed: 6.9ms preprocess, 197.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 bus, 1 truck, 274.7ms\n","Speed: 6.7ms preprocess, 274.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 297.4ms\n","Speed: 6.2ms preprocess, 297.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 bus, 169.9ms\n","Speed: 8.3ms preprocess, 169.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 172.3ms\n","Speed: 8.4ms preprocess, 172.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\n","0: 384x640 2 cars, 1 bus, 181.1ms\n","Speed: 8.1ms preprocess, 181.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 bus, 192.2ms\n","Speed: 5.1ms preprocess, 192.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 bus, 193.2ms\n","Speed: 5.3ms preprocess, 193.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 217.9ms\n","Speed: 7.0ms preprocess, 217.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 188.2ms\n","Speed: 4.3ms preprocess, 188.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 193.8ms\n","Speed: 4.2ms preprocess, 193.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 163.8ms\n","Speed: 5.0ms preprocess, 163.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 161.4ms\n","Speed: 4.7ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 181.3ms\n","Speed: 7.6ms preprocess, 181.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 255.3ms\n","Speed: 9.6ms preprocess, 255.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 266.8ms\n","Speed: 4.6ms preprocess, 266.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 278.7ms\n","Speed: 13.4ms preprocess, 278.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 302.7ms\n","Speed: 11.0ms preprocess, 302.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 171.0ms\n","Speed: 4.3ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 173.8ms\n","Speed: 4.4ms preprocess, 173.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\n","0: 384x640 2 cars, 281.6ms\n","Speed: 5.9ms preprocess, 281.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 189.7ms\n","Speed: 5.4ms preprocess, 189.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 172.6ms\n","Speed: 4.3ms preprocess, 172.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 171.8ms\n","Speed: 4.6ms preprocess, 171.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 171.5ms\n","Speed: 6.1ms preprocess, 171.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 183.4ms\n","Speed: 4.4ms preprocess, 183.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 163.7ms\n","Speed: 5.1ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 167.3ms\n","Speed: 5.3ms preprocess, 167.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 167.7ms\n","Speed: 4.9ms preprocess, 167.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 1 truck, 201.0ms\n","Speed: 4.7ms preprocess, 201.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 cars, 185.9ms\n","Speed: 4.3ms preprocess, 185.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 171.7ms\n","Speed: 5.8ms preprocess, 171.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 175.3ms\n","Speed: 4.5ms preprocess, 175.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 190.1ms\n","Speed: 7.8ms preprocess, 190.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 180.9ms\n","Speed: 6.9ms preprocess, 180.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\n","0: 384x640 1 car, 1 truck, 163.7ms\n","Speed: 3.9ms preprocess, 163.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 1 truck, 168.8ms\n","Speed: 5.8ms preprocess, 168.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 169.8ms\n","Speed: 4.3ms preprocess, 169.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 179.7ms\n","Speed: 6.0ms preprocess, 179.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 177.6ms\n","Speed: 4.6ms preprocess, 177.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 164.5ms\n","Speed: 5.6ms preprocess, 164.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 259.5ms\n","Speed: 4.1ms preprocess, 259.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 254.1ms\n","Speed: 4.2ms preprocess, 254.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 292.3ms\n","Speed: 5.3ms preprocess, 292.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 265.9ms\n","Speed: 8.3ms preprocess, 265.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 172.2ms\n","Speed: 4.8ms preprocess, 172.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 152.1ms\n","Speed: 4.8ms preprocess, 152.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 152.1ms\n","Speed: 4.9ms preprocess, 152.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 car, 178.0ms\n","Speed: 4.0ms preprocess, 178.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"]}]}]}